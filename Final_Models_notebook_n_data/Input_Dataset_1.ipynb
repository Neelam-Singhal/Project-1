{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "## Manual Updates to file:\r\n",
    "- Convert excel file with three tabs to 3 CSV files\r\n",
    "- Put dependent and independent variables in same file.\r\n",
    "- Update column names for easier modelling\r\n",
    "    - Replace space with _ to ensure easier readability\r\n",
    "\r\n",
    "## Data Preprocessing\r\n",
    "1. Convert all -1 to 0.\r\n",
    "2. Remove Skewness from the data\r\n",
    "\r\n",
    "## Data Analysis:\r\n",
    "1. Check number of unique values\r\n",
    "2. Check if missing values\r\n",
    "3. Check Std. Deviation, min, max, quantiles etc"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Variable Description\r\n",
    "    Var 1\tInteger (min=0, no max)\r\n",
    "    Var 2\tReal (min=0, no max)\r\n",
    "    Var 3\tInteger (min=0, no max)\r\n",
    "    Var 4\tReal (Negative value possible though unlikely, no max)\r\n",
    "    Var 5\tOne of 8 classes (so -1 here means not in that class)\r\n",
    "    Var 6\tOne of 12 classes (so -1 here means not in that class)\t\r\n",
    "    Var 7\tInteger\r\n",
    "    Var 8\tInteger\r\n",
    "    Var 9\tInteger\r\n",
    "    Var 10\tInteger\r\n",
    "    Var 11\tReal (no min or max)\r\n",
    "    Var 12\tReal (no min or max)\r\n",
    "    Var 13\tInteger (min=2, no max)"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "source": [
    "import pandas as pd\r\n",
    "import numpy as np\r\n",
    "import matplotlib.pyplot as plt\r\n",
    "import seaborn as sns\r\n",
    "\r\n",
    "# To plot QQ plot\r\n",
    "import statsmodels.api as sm\r\n",
    "\r\n",
    "import warnings\r\n",
    "warnings.filterwarnings('ignore')"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "source": [
    "# To view all the columns \r\n",
    "pd.set_option(\"display.max_columns\", None)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "source": [
    "data = pd.read_csv('Input_Set_1.csv')"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "source": [
    "data.head()"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "   Var_1     Var_2  Var_3      Var_4  Var_5_Class_1  Var_5_Class_2  \\\n",
       "0      5  0.933060     63  15.566940             -1             -1   \n",
       "1      8  2.124317     18  14.375683             -1             -1   \n",
       "2     18  1.618852     53  14.881148             -1             -1   \n",
       "3     11  1.005464     12  15.494536             -1             -1   \n",
       "4     12  1.008197     11  14.274590             -1             -1   \n",
       "\n",
       "   Var_5_Class_3  Var_5_Class_4  Var_5_Class_5  Var_5_Class_6  Var_5_Class_7  \\\n",
       "0             -1             -1             -1             -1             -1   \n",
       "1             -1             -1             -1             -1              1   \n",
       "2             -1             -1             -1             -1              1   \n",
       "3             -1             -1             -1             -1             -1   \n",
       "4             -1             -1             -1             -1             -1   \n",
       "\n",
       "   Var_5_Class_8  Var_6_Class_1  Var_6_Class_2  Var_6_Class_3  Var_6_Class_4  \\\n",
       "0              1              1             -1             -1             -1   \n",
       "1             -1              1             -1             -1             -1   \n",
       "2             -1              1             -1             -1             -1   \n",
       "3              1              1             -1             -1             -1   \n",
       "4              1             -1             -1              1             -1   \n",
       "\n",
       "   Var_6_Class_5  Var_6_Class_6  Var_6_Class_7  Var_6_Class_8  Var_6_Class_9  \\\n",
       "0             -1             -1             -1             -1             -1   \n",
       "1             -1             -1             -1             -1             -1   \n",
       "2             -1             -1             -1             -1             -1   \n",
       "3             -1             -1             -1             -1             -1   \n",
       "4             -1             -1             -1             -1             -1   \n",
       "\n",
       "   Var_6_Class_10  Var_6_Class_11  Var_6_Class_12  Var_7  Var_8  Var_9  \\\n",
       "0              -1              -1              -1      1      0     -1   \n",
       "1              -1              -1              -1      1      2     -1   \n",
       "2              -1              -1              -1      1      0     -1   \n",
       "3              -1              -1              -1      1      0     -1   \n",
       "4              -1              -1              -1      2      0     -1   \n",
       "\n",
       "   Var_10     Var_11     Var_12  Var_13  Input_Data_Set_1  \n",
       "0      -1  39.737157  28.386285       2                 1  \n",
       "1      -1  39.737157  28.386285       2                 0  \n",
       "2      -1  39.737157  28.386285       2                 1  \n",
       "3      -1  39.737157  28.386285       2                 1  \n",
       "4      -1  39.737157  28.386285       2                 1  "
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Var_1</th>\n",
       "      <th>Var_2</th>\n",
       "      <th>Var_3</th>\n",
       "      <th>Var_4</th>\n",
       "      <th>Var_5_Class_1</th>\n",
       "      <th>Var_5_Class_2</th>\n",
       "      <th>Var_5_Class_3</th>\n",
       "      <th>Var_5_Class_4</th>\n",
       "      <th>Var_5_Class_5</th>\n",
       "      <th>Var_5_Class_6</th>\n",
       "      <th>Var_5_Class_7</th>\n",
       "      <th>Var_5_Class_8</th>\n",
       "      <th>Var_6_Class_1</th>\n",
       "      <th>Var_6_Class_2</th>\n",
       "      <th>Var_6_Class_3</th>\n",
       "      <th>Var_6_Class_4</th>\n",
       "      <th>Var_6_Class_5</th>\n",
       "      <th>Var_6_Class_6</th>\n",
       "      <th>Var_6_Class_7</th>\n",
       "      <th>Var_6_Class_8</th>\n",
       "      <th>Var_6_Class_9</th>\n",
       "      <th>Var_6_Class_10</th>\n",
       "      <th>Var_6_Class_11</th>\n",
       "      <th>Var_6_Class_12</th>\n",
       "      <th>Var_7</th>\n",
       "      <th>Var_8</th>\n",
       "      <th>Var_9</th>\n",
       "      <th>Var_10</th>\n",
       "      <th>Var_11</th>\n",
       "      <th>Var_12</th>\n",
       "      <th>Var_13</th>\n",
       "      <th>Input_Data_Set_1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5</td>\n",
       "      <td>0.933060</td>\n",
       "      <td>63</td>\n",
       "      <td>15.566940</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>39.737157</td>\n",
       "      <td>28.386285</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>8</td>\n",
       "      <td>2.124317</td>\n",
       "      <td>18</td>\n",
       "      <td>14.375683</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>39.737157</td>\n",
       "      <td>28.386285</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>18</td>\n",
       "      <td>1.618852</td>\n",
       "      <td>53</td>\n",
       "      <td>14.881148</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>39.737157</td>\n",
       "      <td>28.386285</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>11</td>\n",
       "      <td>1.005464</td>\n",
       "      <td>12</td>\n",
       "      <td>15.494536</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>39.737157</td>\n",
       "      <td>28.386285</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>12</td>\n",
       "      <td>1.008197</td>\n",
       "      <td>11</td>\n",
       "      <td>14.274590</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>39.737157</td>\n",
       "      <td>28.386285</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "metadata": {},
     "execution_count": 4
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Data Analysis"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "source": [
    "# Check shape of the data\r\n",
    "data.shape"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "(1649, 32)"
      ]
     },
     "metadata": {},
     "execution_count": 5
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "source": [
    "# Check how many unique values are there is the data. Helps to understand which column can be set as categorical vs numeric\r\n",
    "data.nunique()"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "Var_1                 52\n",
       "Var_2               1007\n",
       "Var_3                 85\n",
       "Var_4               1379\n",
       "Var_5_Class_1          2\n",
       "Var_5_Class_2          2\n",
       "Var_5_Class_3          2\n",
       "Var_5_Class_4          2\n",
       "Var_5_Class_5          1\n",
       "Var_5_Class_6          2\n",
       "Var_5_Class_7          2\n",
       "Var_5_Class_8          2\n",
       "Var_6_Class_1          2\n",
       "Var_6_Class_2          2\n",
       "Var_6_Class_3          2\n",
       "Var_6_Class_4          2\n",
       "Var_6_Class_5          2\n",
       "Var_6_Class_6          2\n",
       "Var_6_Class_7          2\n",
       "Var_6_Class_8          2\n",
       "Var_6_Class_9          2\n",
       "Var_6_Class_10         2\n",
       "Var_6_Class_11         2\n",
       "Var_6_Class_12         2\n",
       "Var_7                  6\n",
       "Var_8                 13\n",
       "Var_9                  2\n",
       "Var_10                 2\n",
       "Var_11                15\n",
       "Var_12                15\n",
       "Var_13                15\n",
       "Input_Data_Set_1       2\n",
       "dtype: int64"
      ]
     },
     "metadata": {},
     "execution_count": 6
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "source": [
    "# Check if there are any null values\r\n",
    "data.isnull().sum()"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "Var_1               0\n",
       "Var_2               0\n",
       "Var_3               0\n",
       "Var_4               0\n",
       "Var_5_Class_1       0\n",
       "Var_5_Class_2       0\n",
       "Var_5_Class_3       0\n",
       "Var_5_Class_4       0\n",
       "Var_5_Class_5       0\n",
       "Var_5_Class_6       0\n",
       "Var_5_Class_7       0\n",
       "Var_5_Class_8       0\n",
       "Var_6_Class_1       0\n",
       "Var_6_Class_2       0\n",
       "Var_6_Class_3       0\n",
       "Var_6_Class_4       0\n",
       "Var_6_Class_5       0\n",
       "Var_6_Class_6       0\n",
       "Var_6_Class_7       0\n",
       "Var_6_Class_8       0\n",
       "Var_6_Class_9       0\n",
       "Var_6_Class_10      0\n",
       "Var_6_Class_11      0\n",
       "Var_6_Class_12      0\n",
       "Var_7               0\n",
       "Var_8               0\n",
       "Var_9               0\n",
       "Var_10              0\n",
       "Var_11              0\n",
       "Var_12              0\n",
       "Var_13              0\n",
       "Input_Data_Set_1    0\n",
       "dtype: int64"
      ]
     },
     "metadata": {},
     "execution_count": 7
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Data Preprocessing"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "We need to convert all -1 to 0 to help machine understand it better"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "source": [
    "# Saving all the columns which have -1 and 0 values in data_columns variable\r\n",
    "data_columns = ['Var_5_Class_1', 'Var_5_Class_2','Var_5_Class_3', 'Var_5_Class_4', 'Var_5_Class_5', 'Var_5_Class_6','Var_5_Class_7', 'Var_5_Class_8', 'Var_6_Class_1', 'Var_6_Class_2', 'Var_6_Class_3', 'Var_6_Class_4', 'Var_6_Class_5', 'Var_6_Class_6','Var_6_Class_7', 'Var_6_Class_8', 'Var_6_Class_9', 'Var_6_Class_10','Var_6_Class_11', 'Var_6_Class_12', 'Var_9', 'Var_10']"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "source": [
    "# Creating a function to convert all -1 to 0s\r\n",
    "\r\n",
    "def convert_to_zero(df):\r\n",
    "    for i in data_columns:\r\n",
    "        for j in range(len(df)):\r\n",
    "            if (df[i][j] == -1):\r\n",
    "                df[i][j] = 0\r\n",
    "            "
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "source": [
    "convert_to_zero(data)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Oversample minority class"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "source": [
    "data[data.Input_Data_Set_1==0].shape, data[data.Input_Data_Set_1==1].shape"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "((141, 32), (1508, 32))"
      ]
     },
     "metadata": {},
     "execution_count": 11
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "source": [
    "from sklearn.utils import resample\r\n",
    "\r\n",
    "# separate minority and majority classes\r\n",
    "not_accept = data[data.Input_Data_Set_1==0]\r\n",
    "accept = data[data.Input_Data_Set_1==1]\r\n",
    "\r\n",
    "# upsample minority\r\n",
    "not_accept_upsampled = resample(not_accept,\r\n",
    "                          replace=True, # sample with replacement\r\n",
    "                          n_samples=len(accept), # match number in majority class\r\n",
    "                          random_state=27) # reproducible results\r\n",
    "\r\n",
    "# combine majority and upsampled minority\r\n",
    "data = pd.concat([not_accept_upsampled, accept])"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "source": [
    "data[data.Input_Data_Set_1==0].shape, data[data.Input_Data_Set_1==1].shape"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "((1508, 32), (1508, 32))"
      ]
     },
     "metadata": {},
     "execution_count": 13
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "source": [
    "# Saving the preprocessed data in a seperate csv file so that we don't have to repeat above steps multiple times\r\n",
    "data.to_csv(\"Input_Set_1_upsample.csv\", index=False)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Preprocess the data"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "source": [
    "# Capturing the cleaned data\r\n",
    "data = pd.read_csv('Input_Set_1_upsample.csv')"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "source": [
    "data.shape"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "(3016, 32)"
      ]
     },
     "metadata": {},
     "execution_count": 16
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "source": [
    "data_numeric = ['Var_1', 'Var_2', 'Var_3', 'Var_4', 'Var_7', 'Var_8', 'Var_11', 'Var_12', 'Var_13']"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "-0.5 to 0.5 -> Symmetric </br>\r\n",
    "Less than -0.5 -> Negatively Skewed </br>\r\n",
    "More then 0.5 -> Positively Skewed </br></br>\r\n"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "source": [
    "# Function to idenfity skewness\r\n",
    "def data_skewness(df):\r\n",
    "    for i in data_numeric:\r\n",
    "        print(i, \":  \", df[i].skew())"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "source": [
    "data_skewness(data)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Var_1 :   1.027241434363162\n",
      "Var_2 :   1.3818735456853921\n",
      "Var_3 :   7.0346142907058065\n",
      "Var_4 :   -1.902955030278428\n",
      "Var_7 :   5.075627117627829\n",
      "Var_8 :   2.732960748022389\n",
      "Var_11 :   -1.116088537753502\n",
      "Var_12 :   -1.0958683660079687\n",
      "Var_13 :   -0.5421474178256848\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "source": [
    "# Removing skewness. Taking root for positive skewed data and power for negatively skewed data\r\n",
    "data[\"Var_1\"] = np.sqrt(data[\"Var_1\"])\r\n",
    "data[\"Var_2\"] = np.sqrt(data[\"Var_2\"])\r\n",
    "data[\"Var_3\"] = np.cbrt(data[\"Var_3\"])\r\n",
    "data[\"Var_7\"] = np.cbrt(data[\"Var_7\"])\r\n",
    "data[\"Var_8\"] = np.cbrt(data[\"Var_8\"])"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "source": [
    "\r\n",
    "data[\"Var_11\"] = np.power(data[\"Var_11\"], 5)\r\n",
    "data[\"Var_4\"] = np.power(data[\"Var_4\"], 6)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "source": [
    "data_skewness(data)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Var_1 :   -0.635583238338176\n",
      "Var_2 :   0.6540856233795456\n",
      "Var_3 :   0.31394838153338317\n",
      "Var_4 :   -0.2782315762868648\n",
      "Var_7 :   3.643283281249254\n",
      "Var_8 :   0.7158652674997894\n",
      "Var_11 :   0.5092978371936222\n",
      "Var_12 :   -1.0958683660079687\n",
      "Var_13 :   -0.5421474178256848\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Model Building\r\n",
    "We are building RandomForest model as it is less impacted by outliers"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "source": [
    "# After model building, we identified various features which were less important to model building. So we removed those. \r\n",
    "\r\n",
    "model_data = data.drop(['Var_5_Class_1', 'Var_5_Class_3', 'Var_5_Class_4', 'Var_5_Class_5', 'Var_10'], axis=1)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "We will be using two ways to test out model:\r\n",
    "- Train test split\r\n",
    "- Cross Validation"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "source": [
    "# Segregating data in independent and dependent variables\r\n",
    "\r\n",
    "X = model_data.drop(['Input_Data_Set_1'], axis=1)\r\n",
    "y = model_data['Input_Data_Set_1']"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "source": [
    "from sklearn.model_selection import train_test_split\r\n",
    "\r\n",
    "train_X, test_X, train_y, test_y = train_test_split(X, y, random_state=122, stratify = y)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "source": [
    "from sklearn.metrics import f1_score, accuracy_score\r\n",
    "from sklearn.model_selection import RepeatedStratifiedKFold\r\n",
    "from sklearn.model_selection import cross_val_score\r\n",
    "from numpy import mean\r\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Random Forest"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\r\n",
    "\r\n",
    "rf_model = RandomForestClassifier(n_estimators=10, random_state=22)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "source": [
    "# define evaluation procedure\r\n",
    "cv = RepeatedStratifiedKFold(n_splits=10, n_repeats=3, random_state=1)\r\n",
    "# evaluate model\r\n",
    "scores = cross_val_score(rf_model, X, y, scoring='accuracy', cv=cv, n_jobs=-1)\r\n",
    "# summarize performance\r\n",
    "print('Accuracy %.3f' % mean(scores))"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Accuracy 0.979\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "source": [
    "# Fitting a single model using train test split\r\n",
    "rf_model.fit(train_X, train_y)\r\n",
    "\r\n",
    "rf_predicted_test = rf_model.predict(test_X)\r\n",
    "accuracy_rf = accuracy_score(rf_predicted_test, test_y)\r\n",
    "accuracy_rf"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "0.9840848806366048"
      ]
     },
     "metadata": {},
     "execution_count": 29
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "source": [
    "# Checking feature importance to identify features that can be eliminated.\r\n",
    "feature_importance_rf = pd.Series(rf_model.feature_importances_, index=train_X.columns)\r\n",
    "\r\n",
    "feature_importance_rf = feature_importance_rf.sort_values(ascending=False)\r\n",
    "\r\n",
    "feature_importance_rf"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "Var_2             0.136398\n",
       "Var_4             0.135844\n",
       "Var_3             0.129917\n",
       "Var_13            0.091716\n",
       "Var_1             0.090806\n",
       "Var_12            0.060937\n",
       "Var_11            0.057764\n",
       "Var_8             0.057019\n",
       "Var_9             0.029804\n",
       "Var_6_Class_8     0.019424\n",
       "Var_7             0.018991\n",
       "Var_6_Class_1     0.018056\n",
       "Var_5_Class_8     0.017751\n",
       "Var_6_Class_11    0.016723\n",
       "Var_6_Class_2     0.015615\n",
       "Var_5_Class_7     0.014671\n",
       "Var_6_Class_7     0.013406\n",
       "Var_6_Class_10    0.011416\n",
       "Var_6_Class_9     0.010648\n",
       "Var_6_Class_6     0.010367\n",
       "Var_6_Class_5     0.010324\n",
       "Var_6_Class_3     0.009442\n",
       "Var_6_Class_4     0.007935\n",
       "Var_6_Class_12    0.007467\n",
       "Var_5_Class_2     0.005333\n",
       "Var_5_Class_6     0.002228\n",
       "dtype: float64"
      ]
     },
     "metadata": {},
     "execution_count": 30
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Prediction\r\n",
    "model_name = rf_model"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "source": [
    "predicted_data = pd.read_csv(\"v2_Inputs_for_Full_Predictions_1_imputed.csv\")"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "source": [
    "data_skewness(predicted_data)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Var_1 :   3.9019749056127604\n",
      "Var_2 :   1.2858898594763082\n",
      "Var_3 :   18.706620448485587\n",
      "Var_4 :   -1.2845748252297844\n",
      "Var_7 :   40.15172939399318\n",
      "Var_8 :   10.27761779642971\n",
      "Var_11 :   -1.1923984299476802\n",
      "Var_12 :   -0.1738235400552654\n",
      "Var_13 :   -0.13667133273249232\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "source": [
    "# Removing skewness. Taking root for positive skewed data and power for negatively skewed data\r\n",
    "predicted_data[\"Var_1\"] = np.sqrt(predicted_data[\"Var_1\"])\r\n",
    "predicted_data[\"Var_2\"] = np.sqrt(predicted_data[\"Var_2\"])\r\n",
    "predicted_data[\"Var_3\"] = np.cbrt(predicted_data[\"Var_3\"])\r\n",
    "predicted_data[\"Var_7\"] = np.cbrt(predicted_data[\"Var_7\"])\r\n",
    "predicted_data[\"Var_8\"] = np.cbrt(predicted_data[\"Var_8\"])\r\n",
    "predicted_data[\"Var_11\"] = np.power(predicted_data[\"Var_11\"], 5)\r\n",
    "#predicted_data[\"Var_4\"] = np.power(predicted_data[\"Var_4\"], 6)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "source": [
    "data_skewness(predicted_data)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Var_1 :   0.49872883873460444\n",
      "Var_2 :   0.3576557463036899\n",
      "Var_3 :   0.9441237516931893\n",
      "Var_4 :   -1.2845748252297844\n",
      "Var_7 :   3.992715938235575\n",
      "Var_8 :   0.4007817435375751\n",
      "Var_11 :   -1.1991892847336831\n",
      "Var_12 :   -0.1738235400552654\n",
      "Var_13 :   -0.13667133273249232\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "source": [
    "# After model building, we identified various features which were less important to model building. So we removed those. \r\n",
    "\r\n",
    "model_data = predicted_data.drop(['Var_5_Class_1', 'Var_5_Class_3', 'Var_5_Class_4', 'Var_5_Class_5', 'Var_10'], axis=1)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "source": [
    "predictions = rf_model.predict(model_data)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "source": [
    "predictions_probability = rf_model.predict_proba(model_data)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "source": [
    "predictions_probability_0 = predictions_probability[:,0]"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "source": [
    "predictions_probability_1 = predictions_probability[:,1]"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "source": [
    "predictions_probability_1[:10]"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "array([0.6, 0.5, 0.7, 0.6, 1. , 0.7, 0.9, 0.9, 0.8, 0.8])"
      ]
     },
     "metadata": {},
     "execution_count": 92
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "source": [
    "prediction_confidence = []\r\n",
    "for i in predictions_probability_0:\r\n",
    "    if (i > 0.7):\r\n",
    "        prediction_confidence.append(0)\r\n",
    "    elif (i < 0.3):\r\n",
    "        prediction_confidence.append(100)\r\n",
    "    else:\r\n",
    "        prediction_confidence.append(50)\r\n",
    "        \r\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "source": [
    "predictions_probability_0[30:40]"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "array([0.4, 0.4, 0.5, 0.4, 0.5, 0.3, 0.3, 0.5, 0.2, 0.1])"
      ]
     },
     "metadata": {},
     "execution_count": 94
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "source": [
    "output_file_df = pd.DataFrame({\r\n",
    "    \"DataSet\": 1,\r\n",
    "    \"PredictionSet\": 1,\r\n",
    "    \"Prediction\": predictions,\r\n",
    "   # \"Pred_proba_0\": predictions_probability_0,\r\n",
    "   # \"Pred_proba_1\": predictions_probability_1,\r\n",
    "    \"Confidence\": prediction_confidence\r\n",
    "})"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "source": [
    "output_file_df.to_csv(\"Final_File_DS1_Pred1.csv\", index=False)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  }
 ],
 "metadata": {
  "orig_nbformat": 4,
  "language_info": {
   "name": "python",
   "version": "3.8.2",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.2 64-bit"
  },
  "interpreter": {
   "hash": "a9ed818579b1ba32d90b6b7b1ccc8e0ff75013e2740df16cc93d983c2f1c495e"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}